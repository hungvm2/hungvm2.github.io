<!doctype html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <title> Đọc và phân tích Paper &#34;YOLOv3: An Incremental Improment&#34; (YOLOv3) - HungVM2&#39;s Notes </title>
    <meta name="HandheldFriendly" content="True">
    <meta name="MobileOptimized" content="320">
    <meta name="referrer" content="no-referrer">
    <meta name="description" content="" />
    <meta property="og:site_name" content="HungVM2&#39;s Notes" />
    <meta property="og:locale" content="en_US" />
    <meta property="og:type" content="article" />
    <meta property="og:url" content="https://hungvm2.github.io/blog/grasping-yolov3-content/" />
    <meta property="og:title" content="Đọc và phân tích Paper &#34;YOLOv3: An Incremental Improment&#34; (YOLOv3)" />
    <meta property="og:image" content="https://hungvm2.github.io" />
    <meta property="og:description" content="" />

    <meta name="twitter:card" content="summary_large_image" />
    
    <meta name="twitter:title" content="Đọc và phân tích Paper &#34;YOLOv3: An Incremental Improment&#34; (YOLOv3)" />
    <meta name="twitter:description" content="" />
    <meta name="twitter:image" content="https://hungvm2.github.io" />

    <link rel="canonical" href="https://hungvm2.github.io/blog/grasping-yolov3-content/">

    <link rel="stylesheet" href="https://hungvm2.github.io/css/bootstrap.min.css" />

    
    <link rel="stylesheet" href="https://hungvm2.github.io/css/github-gist.min.css" />
    
    <link rel="stylesheet" href="https://hungvm2.github.io/css/custom.css" />

    
    <link rel="stylesheet" href="https://hungvm2.github.io/css/new-custom.css" />



    
    <link href="https://hungvm2.github.io/index.xml" rel="alternate" type="application/rss+xml" title="HungVM2&#39;s Notes" />
    
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script>
      MathJax = {
        tex: {
          tags: 'all',
        inlineMath: [['$', '$']]
        }
      };
    </script>


<script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
</head>

<body>
    
<div class="mt-xl header">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-auto">
                <a href="https://hungvm2.github.io">
                    <h1 class="name">HungVM2&#39;s notes</h1>
                </a>
            </div>
        </div>

        <div class="row justify-content-center">
            <ul class="nav nav-primary">
                
                <li class="nav-item">
                    <a class="nav-link" href="https://hungvm2.github.io/">
                        
                        Articles
                    </a>
                </li>
                
                <li class="nav-item">
                    <a class="nav-link" href="https://hungvm2.github.io/about">
                        
                        About
                    </a>
                </li>
                
            </ul>
        </div>
    </div>
</div>

<div class="content">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-sm-12 col-lg-8">
                <h1 class="mx-0 mx-md-4 blog-post-title">Đọc và phân tích Paper &#34;YOLOv3: An Incremental Improment&#34; (YOLOv3)</h1>

                <div class="mb-md-4 meta">
                    
                    
                    <span class="author" title="Vũ Minh Hưng">
                        Vũ Minh Hưng
                    </span>
                    
                    

                    <span class="date middot" title='Fri Jul 16 2021 11:28:01 &#43;07'>
                        2021-07-16
                    </span>

                    <span class="reading-time middot">
                        7 min read
                    </span>

                    <div class="d-none d-md-inline tags">
                        <ul class="list-unstyled d-inline">
                            
                        </ul>
                    </div>
                </div>

                <div class="markdown blog-post-content">
                    
    <p>Tiếp theo trong series YOLO, ở bài viết này, chúng ta hãy cùng đọc và phân tích nội dung của paper &ldquo;<strong>YOLOv3: An Incremental Improment</strong>&rdquo; published tháng 4 năm 2018 nhé!</p>
<p>Đây cũng chính là version YOLO cuối cùng được phát triển bởi người tạo ra nó: <strong>Joseph Redmon</strong>. Các version sau này là do tác giả khác kế thừa và tiếp tục cải tiến.</p>
<p>Vì mục đích của series này là muốn đi sâu hơn vào sự tiến hoá của YOLO qua từng version, nên mình sẽ chỉ <strong>tập trung vào kiến trúc</strong> của mô hình, cũng như các <strong>phương pháp tối ưu hiệu năng và độ chính xác (FPS/mAP) mới</strong> được sử dụng so với version trước.</p>
<hr>
<h3 id="i-đọc-paper">I. Đọc Paper</h3>
<blockquote>
<p>Trong phần &ldquo;Đọc Paper&rdquo; này, mình sẽ tóm lược lại những ý chính của tác giả, có bỏ qua một số nội dung không quá quan trọng&hellip; Khi đọc sẽ có các reference (có dạng [<a style="color:red;">?</a>]). Bạn có thể click vào các dấu hỏi đó để dẫn xuống phần &ldquo;Hiểu Paper&rdquo; bên dưới để đọc sâu hơn về vấn đề được đề cập.</p>
<p>Trong paper có một số phần không được tác giả đề cập tới (ví dụ: hàm loss, số grid cell, Reorg layer&hellip;), chỉ có ở trong source code, mình tự đưa vào để dễ nắm bắt hơn nội dung của paper</p>
</blockquote>
<h4 id="1-giới-thiệu-chung-về-model">1. Giới thiệu chung về model</h4>
<p>Model YOLOv3 lơn hơn model trước nhưng cũng chính xác hơn.</p>
<p>Với input size $320 \times 320$, YOLOv2 có độ chính xác tương đương SSD nhưng nhanh hơn 3 lần (22ms, 28.2mAP).</p>
<p>Với metric .5 IOU mAP trên Titan X, YOLOv3 có độ chính xác tương đương RetinaNet nhưng nhanh hơn 3.8 lần ($57.9 AP_{50}/51ms$ so với $57.5 AP{50}/198ms$).</p>
<hr>
<h4 id="2-các-thay-đổicải-tiến-so-với-yolov2">2. Các thay đổi/cải tiến so với YOLOv2</h4>
<h5 id="21-bounding-box-prediction">2.1. Bounding box Prediction</h5>
<p>Các giá trị $b_{x}, b_{y}, b_{w}, b_{y}$ tính tương tự như ở YOLOv2</p>
<p>Confident score $C$ sử dụng Logistic Regression thay vì thuần giá trị IOU như YOLOv2. C = 1 khi bounding box đó có IOU lớn nhất so với ground truth box. Nếu bounding box không có IOU max, nhưng IOU vẫn lớn hơn 1 threshold (tác giả lấy = 0.5), thì không tính loss của prediction đó.</p>
<p>Những bounding box mà không có IOU max thì sẽ không được tính coordinates loss và class loss.</p>
<h5 id="22-class-prediction">2.2. Class Prediction</h5>
<p>Không sử dụng Softmax khi predict giá trị xác suất của các classes trên mỗi Bounding box như ở YOLOv2. Thay vào đó, sử dụng Binary Cross-entropy cho class prediction [<a href="#class_prediction" style="color:red;">?</a>]<a name="class_prediction_b"></a>. Điều này giúp một bounding box có thể thuộc về nhiều class, ví dụ như Open Image Dataset có 2 class Woman và Person overlap nhau.</p>
<h5 id="23-predictions-across-scales">2.3. Predictions across Scales</h5>
<p>Sử dụng ý tưởng tương tự như Feature Pyramid Networks, YOLOv3 sẽ predict các boxes ở 3 tỉ lệ (scale) khác nhau.</p>
<p>Sử dụng 9 Anchor boxes thay vì 5 như YOLOv2. 9 Anchor boxes vẫn được chọn bằng K-means. Các Anchor boxes chia thành 3 scale: [(10×13),(16×30),(33×23)] ; [(30×61),(62×45),(59×119)] ; [(116 × 90),(156 × 198),(373 × 326)].</p>
<p>Output tensor cho mỗi scale (3 Anchor boxes cho mỗi scale):
\begin{equation*}
N \times N \times [3 * (4 + 1 +80)]
\end{equation*}</p>
<h5 id="23-feature-extractor">2.3. Feature Extractor</h5>
<p>Mạng classifer mới có tên là Darknet-53 (có 53 lớp Conv Layers), kết hợp giữa Darknet-19 và ý tưởng của Residual Networks</p>
<div class="text-center my-3">
<figure class="figure">
  <img src="https://hungvm2.github.io/images/yolov3/darknet53.png" alt="Classifier model" class="figure-img">
  <figcaption class="figure-caption">Ảnh 1: Kiến trúc mạng Classifier Darknet-53</figcaption>
</figure>
</div>
<hr>
<h4 id="3-training">3. Training</h4>
<h4 id="31-kiến-trúc-mạng">3.1. Kiến trúc mạng</h4>
<p>Dataset: COCO</p>
<div class="text-center my-3">
<figure class="figure">
  <img src="https://hungvm2.github.io/images/yolov3/yolov3-architecture.png" alt="YOLOv3 Architecture" class="figure-img">
  <figcaption class="figure-caption">Ảnh 2: Kiến trúc mạng detection YOLOv3 với NxN = 416x416</figcaption>
</figure>
</div>
<p>Do Paper YOLOv3 không có bản vẽ chi tiết về kiến trúc của mạng detection nên mình đã tham khảo kiến trúc từ <a href="https://www.researchgate.net/publication/334021766_Deep_learning_approach_to_peripheral_leukocyte_recognition">đây</a></p>
<p>Để hiểu chi tiết hơn về kiến trúc, các bạn có thể xem file yolov3.cfg trong <a href="https://github.com/pjreddie/darknet/blob/master/cfg/yolov3.cfg">source code</a> của tác giả, trong đó:</p>
<ul>
<li><i>[shorcut]</i> : là skip connection của mỗi residual block. Có 11 Res Block tương ứng với 11 [shortcut]</li>
<li><i>[yolo]</i>: là layer output của mỗi scale. Có 3 scale tương ứng với 3 layer [shorcut]</li>
<li><i>[route]</i>: là layer concat với các params là giá trị index của các input. Tham khảo thêm ở <a href="https://github.com/AlexeyAB/darknet/issues/279#issuecomment-397248821">đây</a></li>
</ul>
<p>Output của mỗi predicted bounding box sẽ là: 4 giá trị $x^{t}, y^{t}, w^{t}, h^{t}$; 1 giá trị $C^{t}$ và 80 giá trị $p^{t}(c)$</p>
<p>Output của Network sẽ là tổng hợp của 3 output tương ứng với 3 scale, có kích thước:</p>
<p>\begin{equation*}
N \times N \times [9 * (4 + 1 +80)]
\end{equation*}</p>
<h4 id="32-hàm-loss">3.2. Hàm loss</h4>
<div>
\begin{multline*}
\quad Loss = Loss_{coordinates} + Loss_{class\_prob} + Loss_{IOU}\\
= \Big[ \displaystyle \sum_{i=0}^{S^{2}} \displaystyle \sum_{j=0}^{B} \mathbb{1}_{ij}^{obj} [(x_{ij} - \hat{x}_{ij})^{2} + (y_{ij} - \hat{y}_{ij})^{2}]\\ 
+ \displaystyle \sum_{i=0}^{S^{2}} \displaystyle \sum_{j=0}^{B} \mathbb{1}_{ij}^{obj}[(\sqrt{w_{ij}} - \sqrt{\hat{w}_{ij}})^{2} + (\sqrt{h_{ij}} - \sqrt{\hat{h}_{ij}})^{2} ] \Big]\\
+ \Big[- \displaystyle \sum_{i=0}^{S^{2}} \displaystyle \sum_{j=0}^{B}[C_{i} * \log(\hat{C}_{i}) + (1 - C_{i}) * \log(1 - \hat{C}_{i})] \Big] \\
+ CrossEntropy(p_{i}(c), \hat{p}_{i}(c))\\
\\
\end{multline*}
</div>
<p><strong><em>Gọi:</em></strong></p>
<ul>
<li>$W, H$ là kích thước của input (pixel)</li>
<li>$S_{x}, S_{y}$ là số grid cell theo phương x, y</li>
<li>$cell_{x}, cell_{y}$: kích thước của grid cell ($= W/S_{x} = H/S_{y} = 32$pixel)</li>
<li>$w_{g},h_{g}$ là kích thước ground truth box (pixel)</li>
<li>$w_{p}, h_{p}$ là kích thước predicted box (pixel)</li>
<li>$x_{g}, y_{g}$ là vị trí tâm của ground truth box (pixel)</li>
<li>$x_{p}, y_{p}$ là vị trí tâm của predicted box (pixel)</li>
<li>i: là thứ tự của grid cell trong $S_{x} \times S_{y}$ cells</li>
<li>j: là thứ tự của Anchor box trong B Anchors</li>
<li>$\hat{p}_{c}$: giá trị xác suất nhận diện của N class cho ground truth box (20 classes). Có dạng $[0,0,..1,&hellip;0,0,0]$. Vị trí của số $1$ là index của class trong N class.</li>
<li>$P_{c}$: vector N chiều, giá trị xác suất của predicted box (20 classes)</li>
<li>C: confident score, là giá trị IOU max của ground truth box với các anchor box trên 1 grid cell. (trường hợp grid cell có 2 ground truth box trở nên thì sẽ có 2 IOU max trở lên)</li>
<li>$\hat{C}$: confident score của ground truth box</li>
<li>$\hat{x}, \hat{y}, \hat{w}, \hat{h}$: là các giá trị coordinates của ground truth đã được biến đổi.</li>
<li>$x, y, w, h$: là các giá trị của predicted box đã được biến đổi. Tính lại từ công thức <a style="color:red;">(\ref{ref_b})</a></li>
</ul>
<p><strong><em>Các giá trị sẽ được biến đổi như bên dưới:</em></strong></p>
<div>
\begin{multline*}
\\
\hat{x} = (x_{g} \quad \% \quad S_{x}) / cell_{x}\\
\hat{y} = (y_{g} \quad \% \quad S_{y}) / cell_{y}\\
\hat{w} = w_{g} / W\\
\hat{h} = h_{g} / H\\
\hat{p}(c) \quad \text{có dạng} \quad [0,0,1,....,0]\\
\hat{C} = 1\\
\\
x = \sigma{(t_{x})} / cell_x\\
y = \sigma{(t_{y})} / cell_y\\
w = (p_{w} \times e^{t_{w}}) / W\\
h = (p_{h} \times e^{t_{h}}) / H\\
p(c) = Softmax(P_{c})\\
C = IOU_{max}\\
\\
\end{multline*}
</div>
<hr>
<h4 id="4-inference-testing">4. Inference (Testing)</h4>
<p><strong><em>Pipe line của hệ thống object detection YOLOv3:</em></strong></p>
<p>Image $(W,H,3) \Rightarrow $ Network Prediction $\Rightarrow $ Output $(W/8,H/8,255), (W/16,H/16,255), (W/32,H/32,255) \Rightarrow $ Tính lại coordinates box theo W,H ; tính lại class probabilities $Pr(c) \Rightarrow $ Bỏ qua các box có low probabilities $\Rightarrow $ Non-max suppression $\Rightarrow $ Final prediction.</p>
<hr>
<h4 id="5-so-sánh-độ-chính-xác-và-hiệu-năng-với-các-mô-hình-khác">5. So sánh độ chính xác và hiệu năng với các mô hình khác:</h4>
<p>YOLOv3 vẫn tiếp tục đạt độ chính xác tương đương các model khác, trong khi nhanh hơn nhiều lần</p>
<div class="text-center my-3">
<figure class="figure">
  <img src="https://hungvm2.github.io/images/yolov3/ap-comparision.png" alt="AP comparision" class="figure-img">
  <figcaption class="figure-caption">So sánh YOLOv3 với các phương pháp detection one-stage và two-stage</figcaption>
</figure>
</div>
<div class="text-center my-3">
<img src="https://hungvm2.github.io/images/yolov3/ms-comparision.png" class="img-fluid" alt="AP/Time Comparision on COCO dataset">
</div>
<hr>
<h3 id="ii-hiểu-paper">II. Hiểu Paper</h3>
<blockquote>
<p>Trong phần &ldquo;Hiểu Paper&rdquo; này, mình sẽ đi vào phân tích cũng như dẫn lại các giải thích của tác giả về các lý do tại sao tác giả chọn hướng tiếp cận đó, cũng như các thuật ngữ, công thức trong paper&hellip;</p>
</blockquote>
<p>[<a href="#class_prediction_b" style="color:red;">$ \triangleleft $</a>]<a name="class_prediction"></a>:<strong>Class prediction được tính lại như thế nào?</strong></p>
<p>Ở trong bài viết về YOLOv2, loss của class prediction sử dụng <b>sum square error</b>, và các giá trị class prediction của bounding box trước khi đưa vào hàm loss thì phải được transform về dạng sau: $p(c) = Softmax(P_{c})$</p>
<p>Ở YOLOv3, các giá trị class prediction sẽ được giữ nguyên từ output của network, và loss của class prediction sẽ được tính lại theo công thức <b>cross-entropy</b> như sau:</p>
<div>
\begin{equation*}
Loss_{class\_prob}) = - \displaystyle \sum_{i=0}^{S^{2}} \displaystyle \sum_{j=0}^{B} \mathbb{1}_{ij}^{obj} \displaystyle \sum_{c \in classes}p_{ij}(c)log(\hat{p}_{ij}(c))
\end{equation*}
</div>
<hr>
<h3 id="iii-nguồn-tham-khảo">III. Nguồn tham khảo:</h3>
<ul>
<li><a href="https://arxiv.org/abs/1804.02767">YOLOv3: An Incremental Improvement</a></li>
<li><a href="https://github.com/pjreddie/darknet">Darknet</a></li>
<li><a href="https://towardsdatascience.com/yolo-v3-object-detection-53fb7d3bfe6b">What’s new in YOLO v3?</a></li>
<li><a href="https://github.com/eriklindernoren/PyTorch-YOLOv3">Pytorch-YOLOv3</a></li>
</ul>



                </div>

                
            </div>
        </div>
    </div>
</div>





    

    
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/highlight.min.js" integrity="sha512-TDKKr+IvoqZnPzc3l35hdjpHD0m+b2EC2SrLEgKDRWpxf2rFCxemkgvJ5kfU48ip+Y+m2XVKyOCD85ybtlZDmw==" crossorigin="anonymous"></script>
        
            <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/r.min.js" defer></script>
        
            <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/python.min.js" defer></script>
        
            <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/stan.min.js" defer></script>
        
        <script>
            window.addEventListener('load', function() {
                hljs.initHighlighting();
            }, true);
        </script>
    

    

    



</body>
</html>
